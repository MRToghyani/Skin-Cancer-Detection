{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":9011322,"sourceType":"datasetVersion","datasetId":5429371},{"sourceId":9018679,"sourceType":"datasetVersion","datasetId":5428818}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn \nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils import resample\nfrom torchvision.transforms import v2\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport os \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport glob \nfrom random import sample\nfrom tqdm.notebook import tqdm, trange\nfrom torchvision.transforms import v2\nfrom torchmetrics.classification import BinaryPrecision\nfrom torchmetrics.classification import BinaryRecall\nfrom torchmetrics.classification import BinaryAccuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:05:14.832219Z","iopub.execute_input":"2024-07-25T15:05:14.832616Z","iopub.status.idle":"2024-07-25T15:05:14.839809Z","shell.execute_reply.started":"2024-07-25T15:05:14.832583Z","shell.execute_reply":"2024-07-25T15:05:14.838559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img =cv.imread(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0028933.jpg\")\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:05:15.02784Z","iopub.execute_input":"2024-07-25T15:05:15.028342Z","iopub.status.idle":"2024-07-25T15:05:15.573868Z","shell.execute_reply.started":"2024-07-25T15:05:15.028303Z","shell.execute_reply":"2024-07-25T15:05:15.572683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img =cv.imread(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0028933.jpg\")\n\nimg_path_list = glob.glob(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/*\")\nprint(len(img_path_list))\n\nprint(img.shape)\nimg_path_sample=sample(img_path_list,9)\n\nplt.figure(figsize=(9,9))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = cv.imread(img_path_sample[i])\n    plt.imshow(img[...,::-1])\n    #plt.title(img.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:27.954954Z","iopub.execute_input":"2024-07-25T15:12:27.95572Z","iopub.status.idle":"2024-07-25T15:12:30.473975Z","shell.execute_reply.started":"2024-07-25T15:12:27.955661Z","shell.execute_reply":"2024-07-25T15:12:30.472809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(9):\n    plt.subplot(3, 3, i+1)\n    img = cv.imread(img_path_sample[i])\n    plt.imshow(img[..., ::-1])\n    plt.axis('off')  # Esto elimina los tick labels\n\nplt.subplots_adjust(wspace=0, hspace=0)  # Esto elimina los espacios entre las imÃ¡genes\nplt.savefig(\"results__2.jpg\", dpi=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:35:18.461474Z","iopub.execute_input":"2024-07-25T15:35:18.462544Z","iopub.status.idle":"2024-07-25T15:35:19.757434Z","shell.execute_reply.started":"2024-07-25T15:35:18.462504Z","shell.execute_reply":"2024-07-25T15:35:19.75635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path_list[100]","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:30.4764Z","iopub.execute_input":"2024-07-25T15:12:30.476821Z","iopub.status.idle":"2024-07-25T15:12:30.483734Z","shell.execute_reply.started":"2024-07-25T15:12:30.476786Z","shell.execute_reply":"2024-07-25T15:12:30.482594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = pd.read_csv(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\")\nmetadata = metadata.astype({'image_id': 'string'})\nmetadata.info()\nprint(metadata.columns)\nmetadata","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:30.485006Z","iopub.execute_input":"2024-07-25T15:12:30.48531Z","iopub.status.idle":"2024-07-25T15:12:30.540089Z","shell.execute_reply.started":"2024-07-25T15:12:30.485283Z","shell.execute_reply":"2024-07-25T15:12:30.538839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/'\nf2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/'\nmetadata[\"path\"] = metadata[\"image_id\"].apply(lambda x : f1+x+'.jpg' if os.path.exists(f1+x+'.jpg') else f2+x+'.jpg')\nmetadata[\"exists\"] = metadata[\"path\"].apply(lambda x: os.path.exists(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:30.542393Z","iopub.execute_input":"2024-07-25T15:12:30.54275Z","iopub.status.idle":"2024-07-25T15:12:38.264909Z","shell.execute_reply.started":"2024-07-25T15:12:30.542719Z","shell.execute_reply":"2024-07-25T15:12:38.26356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata[\"exists\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:38.267227Z","iopub.execute_input":"2024-07-25T15:12:38.267683Z","iopub.status.idle":"2024-07-25T15:12:38.277284Z","shell.execute_reply.started":"2024-07-25T15:12:38.267641Z","shell.execute_reply":"2024-07-25T15:12:38.275817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions:\n    Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec)\n    basal cell carcinoma (bcc),\n    benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl)\n    dermatofibroma (df)\n    melanoma (mel),\n    melanocytic nevi (nv)\n    and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).","metadata":{}},{"cell_type":"code","source":"metadata2 = metadata[metadata.dx != \"akiec\"]\nmetadata2[\"label\"] = metadata[\"dx\"].apply(lambda x: 1 if ((x == \"mel\") or (x == \"bcc\")) else 0 )\nmetadata2[metadata.dx == \"mel\"]\nmetadata2.to_csv(\"metadata.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:38.278872Z","iopub.execute_input":"2024-07-25T15:12:38.279308Z","iopub.status.idle":"2024-07-25T15:12:38.36413Z","shell.execute_reply.started":"2024-07-25T15:12:38.279267Z","shell.execute_reply":"2024-07-25T15:12:38.363043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata[\"dx\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:12:40.897118Z","iopub.execute_input":"2024-07-25T15:12:40.898112Z","iopub.status.idle":"2024-07-25T15:12:40.906737Z","shell.execute_reply.started":"2024-07-25T15:12:40.898073Z","shell.execute_reply":"2024-07-25T15:12:40.905703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = {\n    'nv': 'Non-cancerous',\n    'mel': 'Cancerous',\n    'bkl': 'Non-cancerous',\n    'bcc': 'Cancerous',\n    'akiec': 'Cancerous',\n    'vasc': 'Non-cancerous',\n    'df': 'Non-cancerous'\n}\n\nfontsize = 15\n\n# Calculate value counts for the 'dx' column\nvalue_counts = metadata[\"dx\"].value_counts()\nvalue_counts2 = metadata2[\"label\"].value_counts()\n\n# Assign colors based on cancer status\ncolors = ['red' if categories[category] == 'Cancerous' else 'green' for category in value_counts.index]\n\n# Create a figure and axes\nfig, ax = plt.subplots(1, 2, figsize=(16, 6),sharey=True)\n\n# Plot the first bar chart\nax[0].bar(value_counts.index, value_counts.values, color=colors, edgecolor='black')\nax[0].set_ylabel('Frequency', fontsize=fontsize)\nax[0].set_xticklabels(value_counts.index, rotation=90)\n\n# Create custom legends\nred_patch = plt.Line2D([0], [0], color='red', lw=4, label='Cancerous (malignant)')\ngreen_patch = plt.Line2D([0], [0], color='green', lw=4, label='Non-cancerous (benign)')\nax[0].legend(handles=[red_patch, green_patch], fontsize=fontsize)\n\n# Plot the second bar chart\nax[1].bar(value_counts2.index, value_counts2.values, color=colors, edgecolor='black')\n#ax[1].set_ylabel('Frequency')\nax[1].legend(handles=[red_patch, green_patch], fontsize=fontsize) \n\nax[1].tick_params(axis='x', labelsize=fontsize)\nax[0].tick_params(axis='y', labelsize=fontsize)\n\nax[0].set_xticklabels(value_counts.index, rotation=90, fontsize=fontsize)\n# Show the bar charts\nplt.tight_layout()\nplt.savefig(\"results.jpg\", dpi=100)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:29:08.863594Z","iopub.execute_input":"2024-07-25T15:29:08.864087Z","iopub.status.idle":"2024-07-25T15:29:09.628058Z","shell.execute_reply.started":"2024-07-25T15:29:08.864051Z","shell.execute_reply":"2024-07-25T15:29:09.626877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata2[\"label\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T15:39:12.190014Z","iopub.execute_input":"2024-07-25T15:39:12.190611Z","iopub.status.idle":"2024-07-25T15:39:12.200026Z","shell.execute_reply.started":"2024-07-25T15:39:12.190561Z","shell.execute_reply":"2024-07-25T15:39:12.198828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata2[\"dx\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:35:41.293421Z","iopub.execute_input":"2024-07-25T14:35:41.293875Z","iopub.status.idle":"2024-07-25T14:35:41.304017Z","shell.execute_reply.started":"2024-07-25T14:35:41.293839Z","shell.execute_reply":"2024-07-25T14:35:41.30272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata2[\"label\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:35:25.883966Z","iopub.execute_input":"2024-07-25T14:35:25.884417Z","iopub.status.idle":"2024-07-25T14:35:25.895118Z","shell.execute_reply.started":"2024-07-25T14:35:25.884371Z","shell.execute_reply":"2024-07-25T14:35:25.89396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split the dataset**","metadata":{}},{"cell_type":"code","source":"metadata2.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain ,test = train_test_split(metadata2,\n                               test_size= 0.2,\n                               random_state= 42,\n                               stratify=metadata2[\"label\"]\n                              )\n\ntrain.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = resample(train[train.label == 1],n_samples=3875,random_state=42,replace=True)\ndf2 = resample(train[train.label == 0],n_samples=3875,random_state=42,replace=False)\nbal_train = pd.concat([df1, df2], axis= 0)\nbal_train.reset_index(inplace=True,drop = True)\nbal_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.image_id.duplicated().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bal_train.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bal_train.to_csv(\"balenced_train.csv\")\ntrain.to_csv(\"train.csv\")\ntest.to_csv(\"test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Custom Dataset**","metadata":{}},{"cell_type":"code","source":"transform_main = v2.Compose([\n    \n    v2.Resize(232,interpolation= v2.InterpolationMode.BILINEAR),\n    v2.CenterCrop(224),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),    #ToTensor()\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\ntransform_aug = v2.Compose([\n            v2.RandomRotation(45),\n            v2.RandomHorizontalFlip(0.5)])\n\ntrain_transform = v2.Compose([transform_aug,transform_main])\n\ntrain_transform,transform_aug,transform_main","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:47.377271Z","iopub.execute_input":"2024-07-24T14:26:47.378182Z","iopub.status.idle":"2024-07-24T14:26:47.388323Z","shell.execute_reply.started":"2024-07-24T14:26:47.378147Z","shell.execute_reply":"2024-07-24T14:26:47.387274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ham(Dataset):\n    def __init__(self,csv_dir,transform = None):\n        self.csv_dir = csv_dir\n        self.datas = pd.read_csv(self.csv_dir)\n        self.transform = transform\n        \n    def __getitem__(self,x):\n        \n        path = self.datas.path[x]\n        img = Image.open(path)\n        label = self.datas.label[x]\n        label = torch.tensor(label, dtype = torch.float32)\n        if self.transform:\n            img = self.transform(img)\n            \n        return img, label\n    \n    def __len__(self):\n        return len(self.datas)\n    \ntrain_dataset = ham(\"/kaggle/input/model-data/balenced_train.csv\",train_transform)\ntest_dataset = ham(\"/kaggle/input/model-data/balenced_test.csv\",transform_main)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:47.704396Z","iopub.execute_input":"2024-07-24T14:26:47.704781Z","iopub.status.idle":"2024-07-24T14:26:47.750518Z","shell.execute_reply.started":"2024-07-24T14:26:47.704753Z","shell.execute_reply":"2024-07-24T14:26:47.749653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img,label =train_dataset[150]\nlabel.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:48.011021Z","iopub.execute_input":"2024-07-24T14:26:48.011753Z","iopub.status.idle":"2024-07-24T14:26:48.031749Z","shell.execute_reply.started":"2024-07-24T14:26:48.011718Z","shell.execute_reply":"2024-07-24T14:26:48.030808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset= train_dataset,\n                              batch_size= 64,    #64, 32\n                              shuffle= True\n                              )\ntest_dataloader = DataLoader(dataset= test_dataset,\n                              batch_size= 64,     #64, 32\n                              shuffle= False\n                              )","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:48.525742Z","iopub.execute_input":"2024-07-24T14:26:48.526151Z","iopub.status.idle":"2024-07-24T14:26:48.531624Z","shell.execute_reply.started":"2024-07-24T14:26:48.526109Z","shell.execute_reply":"2024-07-24T14:26:48.53056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model VGG16_BN**","metadata":{}},{"cell_type":"code","source":"Device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDevice","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:30.357459Z","iopub.execute_input":"2024-07-24T14:26:30.358332Z","iopub.status.idle":"2024-07-24T14:26:30.391804Z","shell.execute_reply.started":"2024-07-24T14:26:30.358294Z","shell.execute_reply":"2024-07-24T14:26:30.390754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import vgg16_bn, VGG16_BN_Weights\n\n# Load VGG16_bn with pre-trained weights\nweights_vgg16_bn = VGG16_BN_Weights.IMAGENET1K_V1\nmodel_vgg16_bn = vgg16_bn(weights=weights_vgg16_bn).to('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:30.688493Z","iopub.execute_input":"2024-07-24T14:26:30.689145Z","iopub.status.idle":"2024-07-24T14:26:32.685426Z","shell.execute_reply.started":"2024-07-24T14:26:30.689115Z","shell.execute_reply":"2024-07-24T14:26:32.684323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\n# Freeze all the layers\nfor param in model_vgg16_bn.parameters():\n    param.requires_grad = False\n\n\n# Modify the final fully connected layer\nnum_ftrs = model_vgg16_bn.classifier[6].in_features\nmodel_vgg16_bn.classifier[6] = nn.Linear(num_ftrs, 1)\n\n#for param in model_vgg16_bn.classifier.parameters():\n#    param.requires_grad = True\n\nsummary(model=model_vgg16_bn,\n        input_size=(1, 3, 224, 224),  # make sure this is \"input_size\", not \"input_shape\"\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:32.687224Z","iopub.execute_input":"2024-07-24T14:26:32.68758Z","iopub.status.idle":"2024-07-24T14:26:32.914947Z","shell.execute_reply.started":"2024-07-24T14:26:32.687552Z","shell.execute_reply":"2024-07-24T14:26:32.913956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_vgg16_bn(model, device, train_loader, validation_loader, epochs, lr, name):\n    model.to(device)\n    loss_fn = nn.BCEWithLogitsLoss().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    train_loss, validation_loss = [], []\n    train_acc, validation_acc = [], []\n    \n    with tqdm(range(epochs), unit='epoch') as tepochs:\n        tepochs.set_description('Training')\n        \n        for epoch in tepochs:\n            model.train()\n            running_loss = 0.\n            correct, total = 0, 0\n            \n            for data, target in train_loader:\n                data, target = data.to(device), target.to(device)\n\n                output = model(data).squeeze(dim=1)\n                pred = torch.sigmoid(output)\n                pred = (pred > 0.5).float()\n\n                optimizer.zero_grad()\n                loss = loss_fn(output, target)\n                loss.backward()\n                optimizer.step()\n\n                tepochs.set_postfix(loss=loss.item())\n                running_loss += loss.item()  \n\n                total += target.size(0)\n                correct += (pred == target).sum().item()\n            \n            train_loss.append(running_loss / len(train_loader))\n            train_acc.append(correct / total)\n\n            model.eval()\n            running_loss = 0.\n            correct, total = 0, 0\n\n            for data, target in validation_loader:\n                data, target = data.to(device), target.to(device)\n                \n                output = model(data).squeeze(dim=1)\n                pred = torch.sigmoid(output)\n                pred = (pred > 0.5).float()\n\n                loss = loss_fn(output, target)\n                running_loss += loss.item()\n                \n                total += target.size(0)\n                correct += (pred == target).sum().item()\n\n            validation_loss.append(running_loss / len(validation_loader))\n            validation_acc.append(correct / total)\n            \n            print(f\"Epoches: {epoch}\")\n            print(f\"\\nTrain loss: {train_loss[-1]:.5f} | Train acc: {train_acc[-1]:.5f} \\nValidation loss: {validation_loss[-1]:.5f} | Validation acc: {validation_acc[-1]:.5f}\\n\")\n            \n            if epoch in [0,5,10, 11,25,30,35,39,40]:\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict()\n                }, f\"./model_vgg16_bn_{name}_e{epoch}.pth\")\n            \n        \"\"\"\n        torch.save({\n            'epoch': epochs,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()\n        }, f\"./model_vgg16_bn_{name}_final_{epochs}.pth\")\n        \"\"\"\n        return train_loss, train_acc, validation_loss, validation_acc","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:53.910503Z","iopub.execute_input":"2024-07-24T14:26:53.911421Z","iopub.status.idle":"2024-07-24T14:26:53.926834Z","shell.execute_reply.started":"2024-07-24T14:26:53.911366Z","shell.execute_reply":"2024-07-24T14:26:53.92558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_vgg16_bn, train_acc_vgg16_bn, validation_loss_vgg16_bn, validation_acc_vgg16_bn = train_vgg16_bn(model_vgg16_bn, Device, train_dataloader, test_dataloader, epochs=1, lr=0.0001, name=\"freeze\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T14:26:54.277669Z","iopub.execute_input":"2024-07-24T14:26:54.278306Z","iopub.status.idle":"2024-07-24T14:29:09.842093Z","shell.execute_reply.started":"2024-07-24T14:26:54.278273Z","shell.execute_reply":"2024-07-24T14:29:09.840773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model_vgg16_bn.parameters():\n    param.requires_grad = True\n    \nsummary(model=model_vgg16_bn,\n        input_size=(1, 3, 224, 224),  # make sure this is \"input_size\", not \"input_shape\"\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss2, train_acc2, validation_loss2, validation_acc2= train_vgg16_bn(model_vgg16_bn, Device,train_dataloader,test_dataloader,11, 0.000001, \"finetune\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n\n# # Create a zip archive\n# shutil.make_archive('/kaggle/working/model_vgg16_bn_freeze', 'zip', '/kaggle/working')\n\n# # Now, you can download the zip file from the output section\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}